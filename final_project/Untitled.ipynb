{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "checked-thong",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "import tqdm\n",
    "import lightgbm as lgb\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "shaped-teddy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_calculation_for_train(data,values, count_describe):\n",
    "    count_describe=values\n",
    "    # data = pd.DataFrame(pd.read_csv('/home/alex4/Desktop/AidisTech/hotel/data_by_days.csv'))\n",
    "    df = pd.DataFrame(data.a[values - count_describe:values - 1].describe())\n",
    "    # df.append(data.a[14])\n",
    "\n",
    "    df2 = pd.DataFrame(\n",
    "        [list(data.a[0:values])], columns=(range(values)))\n",
    "    # df2=df2.pivot_table(index=df2.columns,columns='w')\n",
    "    df2.index = [\"a\"]\n",
    "    print(df2.index)\n",
    "    df = df.pivot_table(values=\"a\", columns=df.index)\n",
    "    stat = pd.concat([df, df2], axis=1)\n",
    "    print(stat)\n",
    "    # print(data)\n",
    "    for i in range(values + 1, len(data)):\n",
    "        df = pd.DataFrame(data.a[i - count_describe:i - 1].describe())\n",
    "        df = df.pivot_table(values=\"a\", columns=df.index)\n",
    "        df2 = pd.DataFrame([list(data.a[i - values:i])], columns=(range(values)))\n",
    "        df2.index = [\"a\"]\n",
    "        df = pd.concat([df, df2], axis=1)\n",
    "        print(df)\n",
    "\n",
    "        print(i)\n",
    "        stat = stat.append(df)\n",
    "\n",
    "    # df=pd.DataFrame(data.a[14 - 14:14].describe())\n",
    "    stat = stat.drop([\"count\"], axis=1)\n",
    "    print(stat)\n",
    "    stat.to_csv('/home/alex4/Desktop/AidisTech/final_project/data_for_train.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "compliant-justice",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exelread():\n",
    "    data = pd.DataFrame(pd.read_excel(r'/home/alex4/Desktop/AidisTech/hotel/2019_01.xls', skiprows=8))\n",
    "    print(data.info)\n",
    "    data1 = pd.DataFrame(pd.read_excel('/home/alex4/Desktop/AidisTech/hotel/2019_02.xls', skiprows=8))\n",
    "    data = data.append(data1)\n",
    "    for i in range(2, 25):\n",
    "        print(i)\n",
    "        data1 = pd.DataFrame(\n",
    "            pd.read_excel(f'/home/alex4/Desktop/AidisTech/hotel/Гостинница Северная, профиль мощности ({i}).xls',\n",
    "                          skiprows=8))\n",
    "        data = data.append(data1)\n",
    "    print(data.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "homeless-tours",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_plot_and_error(data,test_data):\n",
    "    # data = pd.DataFrame(pd.read_csv('/home/alex4/Desktop/AidisTech/final_project/data_for_train.csv'))\n",
    "    print(mean_absolute_percentage_error(data, test_data))\n",
    "    plot(data)\n",
    "    plot(test_data)\n",
    "    # print(mean_absolute_percentage_error(Y, y_pred))\n",
    "    # print(\"размер тестовой выборки= \", y_test.size)\n",
    "    # print(\"размер обучающей выборки= \", y_train.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "thermal-netherlands",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_models(data,times,values,score):\n",
    "    res = {'forest': 0, 'GBM': 0, 'xgb': 0, 'cat': 0 ,'lgbm':0}\n",
    "    data = pd.DataFrame(pd.read_csv('data_for_train.csv')).head(762-24)\n",
    "    # data=data.sample(frac=1)\n",
    "    Y = data[str(values)]\n",
    "    data = data.drop([str(values)], axis=1)\n",
    "    # score=0.05\n",
    "    models=[]\n",
    "    for i in tqdm.tqdm(range(times)):\n",
    "        #     print()\n",
    "        #     print(i)\n",
    "        #     print()\n",
    "        # regr = RandomForestRegressor(max_depth=10,n_estimators=100)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data, Y, test_size=0.1,shuffle=True)\n",
    "        regr = RandomForestRegressor(n_estimators=100, max_depth=5)\n",
    "        # shuffle=True=>5%\n",
    "        regr.fit(X_train, y_train)\n",
    "        y_pred = regr.predict(X_test)\n",
    "        error=  mean_absolute_percentage_error(y_test, y_pred)\n",
    "        print(\"forest  \", error)\n",
    "        res['forest'] += error\n",
    "        if error<score:\n",
    "            models.append(regr)\n",
    "        regr = GradientBoostingRegressor(learning_rate=0.1, n_estimators=100, max_depth=5)\n",
    "        # shuffle=True=>5%\n",
    "        regr.fit(X_train, y_train)\n",
    "        y_pred = regr.predict(X_test)\n",
    "        error = mean_absolute_percentage_error(y_test, y_pred)\n",
    "        print(\"GBM  \", error)\n",
    "        res['GBM'] += error\n",
    "        if error < score:\n",
    "            models.append(regr)\n",
    "\n",
    "        regr = xgb.XGBRegressor(max_depth=5, learning_rate=0.1)\n",
    "        # shuffle=True=>5%\n",
    "        regr.fit(X_train, y_train)\n",
    "        y_pred = regr.predict(X_test)\n",
    "        error = mean_absolute_percentage_error(y_test, y_pred)\n",
    "        print(\"xgb  \", error)\n",
    "        res['xgb'] += error\n",
    "        if error <score:\n",
    "            models.append(regr)\n",
    "\n",
    "        regr = CatBoostRegressor(learning_rate=0.1, depth=5, logging_level='Silent')\n",
    "        # shuffle=True=>5%\n",
    "        regr.fit(X_train, y_train)\n",
    "        y_pred = regr.predict(X_test)\n",
    "        error = mean_absolute_percentage_error(y_test, y_pred)\n",
    "        print(\"cat  \", error)\n",
    "        res['cat'] += error\n",
    "        if error <score:\n",
    "            models.append(regr)\n",
    "        regr = lgb.LGBMRegressor(max_depth=5, learning_rate=0.1)\n",
    "        # shuffle=True=>5%\n",
    "        regr.fit(X_train, y_train)\n",
    "        y_pred = regr.predict(X_test)\n",
    "        error = mean_absolute_percentage_error(y_test, y_pred)\n",
    "        print(\"lgbm  \", error)\n",
    "        res['lgbm'] += error\n",
    "        if error < score:\n",
    "            models.append(regr)\n",
    "        # mean(cross_val_score(regr, X_train, y_train, cv=10))\n",
    "    print(\"размер тестовой выборки= \", y_test.size)\n",
    "    print(\"размер обучающей выборки= \", y_train.size)\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "homeless-dutch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacking (models,data):\n",
    "    ans=list()\n",
    "    for model in models:\n",
    "        ans.append(model.predict(data))\n",
    "    return sum(ans)/len(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "architectural-rachel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_n_times(data, values, count_describe, n, model):\n",
    "def predict_n_times(data, values, count_describe, n, models):\n",
    "    data=data.head(len(data)-n)\n",
    "    result= pd.DataFrame(columns=[\"begin\",\"a\"])\n",
    "    for i in range(len(data) - values, len(data) - values + n):\n",
    "        tmp = pd.DataFrame(data.a[i: i + values].describe())\n",
    "        tmp = tmp.drop([\"count\"], axis=0).T\n",
    "        #         tmp\n",
    "        tmp.index = [\"w\"]\n",
    "        data_for_predict = pd.DataFrame(list(data.a[i:i + values])).T\n",
    "        #         print(data_for_predict)\n",
    "        data_for_predict.index = [\"w\"]\n",
    "        data_for_predict = pd.concat([tmp, data_for_predict], axis=1)\n",
    "        # data_for_predict\n",
    "#         model.predict(data_for_predict)\n",
    "#         data = data.append(pd.DataFrame(model.predict(data_for_predict), columns=[\"a\"]), ignore_index=True)\n",
    "        data = data.append(pd.DataFrame(stacking (models,data_for_predict), columns=[\"a\"]), ignore_index=True)\n",
    "        result=result.append(data.tail(1))\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "soviet-surge",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data was rеad\n",
      "forest   0.01549440072247573\n",
      "GBM   0.011684124200385889\n",
      "xgb   0.011836634393006803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 1/3 [00:05<00:11,  5.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat   0.009071907372196486\n",
      "lgbm   0.013058712082235998\n",
      "forest   0.01530460239993211\n",
      "GBM   0.010644396313520888\n",
      "xgb   0.0094454561049275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 2/3 [00:11<00:05,  5.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat   0.008584885045241191\n",
      "lgbm   0.01054065526146444\n",
      "forest   0.013556142552572597\n",
      "GBM   0.011620135004104937\n",
      "xgb   0.010360801595917174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:17<00:00,  5.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat   0.009969877063132744\n",
      "lgbm   0.011747913101128655\n",
      "размер тестовой выборки=  69\n",
      "размер обучающей выборки=  615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['25%', '50%', '75%', 'max', 'mean', 'min', 'std', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58'] ['mean', 'std', 'min', '25%', '50%', '75%', 'max', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-6bd52e77b918>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredict_n_times\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcount_describe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#     print(y_test.info)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-6f05506a45ba>\u001b[0m in \u001b[0;36mpredict_n_times\u001b[0;34m(data, values, count_describe, n, models)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#         model.predict(data_for_predict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#         data = data.append(pd.DataFrame(model.predict(data_for_predict), columns=[\"a\"]), ignore_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstacking\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_for_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-a8a5ac9a499e>\u001b[0m in \u001b[0;36mstacking\u001b[0;34m(models, data)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mans\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, validate_features, base_margin)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mntree_limit\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0mntree_limit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"best_ntree_limit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         return self.get_booster().predict(test_dmatrix,\n\u001b[0m\u001b[1;32m    652\u001b[0m                                           \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m                                           \u001b[0mntree_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features, training)\u001b[0m\n\u001b[1;32m   1483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidate_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1485\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_bst_ulong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_validate_features\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   2058\u001b[0m                             ', '.join(str(s) for s in my_missing))\n\u001b[1;32m   2059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2060\u001b[0;31m                 raise ValueError(msg.format(self.feature_names,\n\u001b[0m\u001b[1;32m   2061\u001b[0m                                             data.feature_names))\n\u001b[1;32m   2062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: feature_names mismatch: ['25%', '50%', '75%', 'max', 'mean', 'min', 'std', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58'] ['mean', 'std', 'min', '25%', '50%', '75%', 'max', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58']"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "#     data = pd.DataFrame(pd.read_csv('/home/alex4/Desktop/AidisTech/hotel/data_by_days.csv'))\n",
    "    data =pd.DataFrame(pd.read_csv('/home/alex4/Desktop/AidisTech/final_project/check_data.csv'))\n",
    "    print(\"data was rеad\")\n",
    "    values=60\n",
    "    n=24\n",
    "#     data_calculation_for_train(data,values,1)\n",
    "\n",
    "    models=test_models(1,1,values-1,score=0.10)\n",
    "    y_pred=predict_n_times(data,values-1,n=n,models=models,count_describe=False)\n",
    "    y_test=data.tail(n)\n",
    "#     print(y_test.info)\n",
    "#     print(y_pred.info)\n",
    "    my_plot_and_error(y_test.a,y_pred.a)\n",
    "#     s\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(data, Y, test_size=0.3)\n",
    "    # model=\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "affiliated-clinton",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_for_predict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-fae854469ce8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# pylab.show()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# pd.DataFrame(pd.read_csv('/home/alex4/Desktop/AidisTech/final_project/check_data.csv'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mstacking\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_for_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data_for_predict' is not defined"
     ]
    }
   ],
   "source": [
    "# y_test.a\n",
    "# y_pred.a\n",
    "# =data.tail(n)\n",
    "# my_plot_and_error(y_test.a,y_pred.a)\n",
    "# plot(y_test.a)\n",
    "# plot(y_pred.a)\n",
    "# pylab.show()\n",
    "# pd.DataFrame(pd.read_csv('/home/alex4/Desktop/AidisTech/final_project/check_data.csv'))\n",
    "stacking (models,data_for_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
